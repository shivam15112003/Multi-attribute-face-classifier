{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEpxA-p7wbUD"
      },
      "source": [
        "Importing the necessaries libaries for the task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "QQ09lJ0OwbUJ",
        "outputId": "04a6caea-5adf-4311-d922-edf57614072c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.applications import VGG16,MobileNetV2\n",
        "from keras.models import Model\n",
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0xHvWofwbUO"
      },
      "source": [
        "Model building,training and testing for age detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JZADZXyuwbUP",
        "outputId": "6dfac025-44c7-47c0-fc13-0739bf51167f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 9479 images belonging to 95 classes.\n",
            "Epoch 1/2\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4504s\u001b[0m 15s/step - accuracy: 0.0150 - loss: 5.8947\n",
            "Epoch 2/2\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4057s\u001b[0m 14s/step - accuracy: 0.0210 - loss: 4.5492\n",
            "Found 2790 images belonging to 95 classes.\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 4s/step - accuracy: 0.0094 - loss: 4.5502\n",
            "the test accuracy was found to be: 4.550000190734863\n"
          ]
        }
      ],
      "source": [
        "# Load the VGGFace model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "# Adding custom layers to the model\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "age_prediction_layer = tf.keras.layers.Dense(95, activation='sigmoid')\n",
        "\n",
        "age_model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        global_average_layer,\n",
        "        age_prediction_layer\n",
        "])\n",
        "\n",
        "# Fine-tune the model\n",
        "age_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Load the training data\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "age_train_generator = train_datagen.flow_from_directory(r'C:\\Users\\Shivam Sharma\\Documents\\Python Scripts\\task3\\datasets\\age_train', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# Train the model\n",
        "age_history = age_model.fit(age_train_generator, epochs=2)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "age_test_generator = train_datagen.flow_from_directory(r'C:\\Users\\Shivam Sharma\\Documents\\Python Scripts\\task3\\datasets\\age_test', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "age_evaluation = age_model.evaluate(age_test_generator)\n",
        "print('the test accuracy was found to be:',age_evaluation[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDCLp-8KwbUP"
      },
      "source": [
        "Model building,training and testing for natioanality detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K43-DklXwbUP",
        "outputId": "78d6d83b-84d9-48ba-b116-02b3fb0b9710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 500 images belonging to 5 classes.\n",
            "Found 150 images belonging to 5 classes.\n",
            "Epoch 1/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 542ms/step - accuracy: 0.2770 - loss: 1.7406 - val_accuracy: 0.4667 - val_loss: 1.2327\n",
            "Epoch 2/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 632ms/step - accuracy: 0.4911 - loss: 1.1769 - val_accuracy: 0.6600 - val_loss: 0.9450\n",
            "Epoch 3/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 468ms/step - accuracy: 0.6708 - loss: 0.9019 - val_accuracy: 0.7600 - val_loss: 0.7641\n",
            "Epoch 4/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 463ms/step - accuracy: 0.7804 - loss: 0.7214 - val_accuracy: 0.8067 - val_loss: 0.6226\n",
            "Epoch 5/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 475ms/step - accuracy: 0.8224 - loss: 0.5953 - val_accuracy: 0.8800 - val_loss: 0.5220\n",
            "Epoch 6/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 491ms/step - accuracy: 0.9230 - loss: 0.4651 - val_accuracy: 0.9000 - val_loss: 0.4288\n",
            "Epoch 7/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 502ms/step - accuracy: 0.9195 - loss: 0.3896 - val_accuracy: 0.9533 - val_loss: 0.3195\n",
            "Epoch 8/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 511ms/step - accuracy: 0.9759 - loss: 0.2890 - val_accuracy: 0.9733 - val_loss: 0.2732\n",
            "Epoch 9/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 515ms/step - accuracy: 0.9866 - loss: 0.2370 - val_accuracy: 0.9867 - val_loss: 0.2154\n",
            "Epoch 10/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 511ms/step - accuracy: 0.9867 - loss: 0.1966 - val_accuracy: 0.9933 - val_loss: 0.1836\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 355ms/step - accuracy: 0.9978 - loss: 0.1839\n",
            "Test accuracy: 0.99\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a new classification head\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "# Define the model\n",
        "nationality_model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "nationality_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load the training data\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(r'C:\\Users\\Shivam Sharma\\Documents\\Python Scripts\\task5\\datasets\\nationality_train', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# Load the validation data'\n",
        "val_generator = train_datagen.flow_from_directory(r'C:\\Users\\Shivam Sharma\\Documents\\Python Scripts\\task5\\datasets\\nationality_test', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# Train the model\n",
        "history = nationality_model.fit(train_generator, epochs=10, validation_data=val_generator)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = nationality_model.evaluate(val_generator)\n",
        "print(f'Test accuracy: {accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2D5AAcZwbUQ"
      },
      "source": [
        "model building, training and testing for dresscode classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9Qq5Fhh9wbUQ",
        "outputId": "8a024331-f78e-40b9-a5b2-a13a2dd06250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 300 images belonging to 3 classes.\n",
            "Found 90 images belonging to 3 classes.\n",
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 317ms/step - accuracy: 0.4978 - loss: 1.0965\n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 318ms/step - accuracy: 0.7426 - loss: 0.6491\n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 327ms/step - accuracy: 0.8557 - loss: 0.3970\n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 332ms/step - accuracy: 0.9161 - loss: 0.2525\n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 330ms/step - accuracy: 0.9623 - loss: 0.2086\n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 334ms/step - accuracy: 0.9785 - loss: 0.1492\n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 324ms/step - accuracy: 0.9904 - loss: 0.1024\n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 339ms/step - accuracy: 0.9931 - loss: 0.0869\n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 336ms/step - accuracy: 0.9869 - loss: 0.0773\n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 331ms/step - accuracy: 0.9827 - loss: 0.0794\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 0.0501\n",
            "Test accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a new classification head\n",
        "d_x = base_model.output\n",
        "d_x = tf.keras.layers.GlobalAveragePooling2D()(d_x)\n",
        "d_x = tf.keras.layers.Dense(128, activation='relu')(d_x)\n",
        "d_x = tf.keras.layers.Dense(3, activation='softmax')(d_x)\n",
        "\n",
        "# Define the model\n",
        "dresscode_model = Model(inputs=base_model.input, outputs=d_x)\n",
        "\n",
        "# Compile the model\n",
        "dresscode_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load the training data\n",
        "train_generator = train_datagen.flow_from_directory(r'C:\\Users\\Shivam Sharma\\Documents\\Python Scripts\\task5\\datasets\\dresscode_train', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# Load the test data\n",
        "test_generator = train_datagen.flow_from_directory(r'C:\\Users\\Shivam Sharma\\Documents\\Python Scripts\\task5\\datasets\\dresscode_test', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# Train the model\n",
        "history = dresscode_model.fit(train_generator, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = dresscode_model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO126GmTwbUR"
      },
      "source": [
        "defining the function to extract the class name from predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_HVAsEYEwbUR"
      },
      "outputs": [],
      "source": [
        "def extract_class_name(predictions, classes):\n",
        "      # Extracting the most likely class index for each prediction\n",
        "      predicted_indices = predictions.argmax(axis=1)\n",
        "\n",
        "      # Geting the corresponding class names\n",
        "      predicted_class_names = [classes[idx] for idx in predicted_indices]\n",
        "\n",
        "      return predicted_class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I4_jkc9wbUS"
      },
      "source": [
        "defining the main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "vh3VKPNzwbUS"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    global window,filename\n",
        "    class_names_age = []\n",
        "    class_names_dresscode=['Casual','Formal','Semi-formal']\n",
        "    class_names_nationality=['African','American','Austrialian','Brazilian','Indian']\n",
        "    for i in range(6,101):\n",
        "        class_names_age.append(str(i))\n",
        "    #read the image file\n",
        "    img = cv2.imread(filename)\n",
        "    # Preprocess the image\n",
        "    img = tf.image.resize(img[None],(224, 224))\n",
        "    #predict the age of the person in image\n",
        "    predictions=age_model.predict(img)\n",
        "    age_predicted_class_name=extract_class_name(predictions,class_names_age)[0]\n",
        "\n",
        "    #rejecting the age below 10 and above 60\n",
        "    if int(age_predicted_class_name)>= 10 and int(age_predicted_class_name)<= 60:\n",
        "        #predict the nationality of the person in image\n",
        "        predictions = nationality_model.predict(img)\n",
        "        nat_predicted_class_name=extract_class_name(predictions,class_names_nationality)\n",
        "        #printing the nationality\n",
        "        message = tk.Message(window, text=f\"the nationality to which person in image belongs is: {nat_predicted_class_name}\")\n",
        "        message.pack()\n",
        "\n",
        "        #predict the emotion\n",
        "        # Analyze the image using DeepFace\n",
        "        face_analysis = DeepFace.analyze(img_path=filename)\n",
        "        # Get the predicted emotion and the dominant emotion\n",
        "        predicted_dominant_emotion = face_analysis[\"dominant_emotion\"]\n",
        "        #printing the emotion\n",
        "        message = tk.Message(window, text=f\"the Emotion of the person in image has identified to be : {predicted_dominant_emotion}\")\n",
        "        message.pack()\n",
        "        if nat_predicted_class_name =='American' or nat_predicted_class_name == 'Indian':\n",
        "            #print the age\n",
        "            message = tk.Message(window, text=f\"the age of the person in image has identified to be: {age_predicted_class_name}\")\n",
        "            message.pack()\n",
        "        if nat_predicted_class_name == 'African' or nat_predicted_class_name == 'Indian':\n",
        "            predictions=dresscode_model.predict(img)\n",
        "            dresscode_predicted_class=extract_class_name(predictions,class_names_dresscode)\n",
        "            #print the dresscode\n",
        "            message = tk.Message(window, text=f\"the dress code of the person in image has identified to be: {dresscode_predicted_class}\")\n",
        "            message.pack()\n",
        "    else:\n",
        "        message = tk.Message(window, text=f\"please provide me the image between 10-60 range!!!\")\n",
        "        message.pack()\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp_mo8aHwbUS"
      },
      "source": [
        "creating window for user interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "eXHITud8wbUS",
        "outputId": "62c56e08-96c8-47e2-ba4c-ba28687d4f2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "window = tk.Tk()\n",
        "window.title(\"Classifying a person’s nationality, emotion, age, and dress code from an image\")\n",
        "window.geometry(\"500x500\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIZmDh1pwbUT"
      },
      "source": [
        "building button for file explorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "_zO2byo3wbUT"
      },
      "outputs": [],
      "source": [
        "label_file_explorer = tk.Label(window, text=\"\")\n",
        "label_file_explorer.pack()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qen8IjNwbUT"
      },
      "source": [
        "function for browsing the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "s39mvYF8wbUT"
      },
      "outputs": [],
      "source": [
        "def browseFiles():\n",
        "    global filename\n",
        "    filename =''\n",
        "    filename = filedialog.askopenfilename(initialdir=\"/\", title=\"Select a file\",filetypes=((\"Image files\", \"*.png;*.jpg;*.jpeg;*.bmp;*.gif\"),\n",
        "                                                 (\"Video files\", \"*.mp4;*.avi;*.mov;*.mkv;*.flv\"), (\"All files\", \"*.*\")))\n",
        "    label_file_explorer.configure(text=\"File Opened: \" + filename)\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrowrWtSwbUT"
      },
      "source": [
        "building upload button"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "HaukoGubwbUT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n"
          ]
        }
      ],
      "source": [
        "label_upload = tk.Label(window, text=\"Upload a image or vedio file:\")\n",
        "label_upload.pack()\n",
        "\n",
        "button_upload = tk.Button(window, text=\"Browse\", command=browseFiles)\n",
        "button_upload.pack()\n",
        "window.mainloop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
